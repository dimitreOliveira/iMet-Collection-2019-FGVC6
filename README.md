![](https://github.com/dimitreOliveira/iMet-Collection-2019-FGVC6/blob/master/Assets/banner.png)

## About the repository
The goal of this repository is to use the data from "iMet Collection 2019 FGVC6" train multi-label models on image data and improve overall skill associated with image modeling, like deep learning, transfer learning, and others.

### My published Kaggle kernels:
- [iMet Collection 2019 - EDA & Keras](https://www.kaggle.com/dimitreoliveira/imet-collection-2019-eda-keras)
- [iMet - Keras pretrained model as feature extractor](https://www.kaggle.com/dimitreoliveira/imet-keras-pretrained-model-as-feature-extractor)

### What you will find
- Documentation [[link]](https://github.com/dimitreOliveira/iMet-Collection-2019-FGVC6/tree/master/Documentation)
  - Project working cycle and effort, relevant content and insights [[link]](https://github.com/dimitreOliveira/iMet-Collection-2019-FGVC6/blob/master/Documentation/Planning.md)
- EDA [[link]](https://github.com/dimitreOliveira/iMet-Collection-2019-FGVC6/tree/master/EDA)
  - iMet Collection 2019 - EDA & Keras [[link]](https://github.com/dimitreOliveira/iMet-Collection-2019-FGVC6/blob/master/EDA/iMet%20Collection%202019%20-%20EDA%20%26%20Keras.ipynb)
- Model [[link]](https://github.com/dimitreOliveira/iMet-Collection-2019-FGVC6/tree/master/Model%20backlog)
  - Complete models [[link]](https://github.com/dimitreOliveira/iMet-Collection-2019-FGVC6/tree/master/Model%20backlog/Deep%20Learning/Complete%20models)
  - DenseNet121 [[link]](https://github.com/dimitreOliveira/iMet-Collection-2019-FGVC6/tree/master/Model%20backlog/Deep%20Learning/DenseNet121)
  - InceptionV3 [[link]](https://github.com/dimitreOliveira/iMet-Collection-2019-FGVC6/tree/master/Model%20backlog/Deep%20Learning/InceptionV3)
  - MobileNetV2 [[link]](https://github.com/dimitreOliveira/iMet-Collection-2019-FGVC6/tree/master/Model%20backlog/Deep%20Learning/MobileNetV2)
  - NasNetLarge [[link]](https://github.com/dimitreOliveira/iMet-Collection-2019-FGVC6/tree/master/Model%20backlog/Deep%20Learning/NasNetLarge)
  - NasNetMobile [[link]](https://github.com/dimitreOliveira/iMet-Collection-2019-FGVC6/tree/master/Model%20backlog/Deep%20Learning/NasNetMobile)
  - ResNet50 [[link]](https://github.com/dimitreOliveira/iMet-Collection-2019-FGVC6/tree/master/Model%20backlog/Deep%20Learning/ResNet50)
  - VGG16 [[link]](https://github.com/dimitreOliveira/iMet-Collection-2019-FGVC6/tree/master/Model%20backlog/Deep%20Learning/VGG16)
  - VGG19 [[link]](https://github.com/dimitreOliveira/iMet-Collection-2019-FGVC6/tree/master/Model%20backlog/Deep%20Learning/VGG19)
  - Xception [[link]](https://github.com/dimitreOliveira/iMet-Collection-2019-FGVC6/tree/master/Model%20backlog/Deep%20Learning/Xception)

### iMet Collection 2019 - FGVC6
#### Recognize artwork attributes from The Metropolitan Museum of Art

Kaggle competition: https://www.kaggle.com/c/imet-2019-fgvc6

### Overview

The Metropolitan Museum of Art in New York, also known as The Met, has a diverse collection of over 1.5M objects of which over 200K have been digitized with imagery. The online cataloging information is generated by Subject Matter Experts (SME) and includes a wide range of data. These include, but are not limited to: multiple object classifications, artist, title, period, date, medium, culture, size, provenance, geographic location, and other related museum objects within The Met’s collection. While the SME-generated annotations describe the object from an art history perspective, they can also be indirect in describing finer-grained attributes from the museum-goer’s understanding. Adding fine-grained attributes to aid in the visual understanding of the museum objects will enable the ability to search for visually related objects.


### About
This is an FGVCx competition hosted as part of the [FGVC6 workshop](https://sites.google.com/view/fgvc6/home) at [CVPR 2019](http://cvpr2019.thecvf.com/). View the [github page](https://github.com/visipedia/imet-fgvcx) for more details.
